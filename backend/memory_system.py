#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é•¿æœŸè®°å¿†ç³»ç»Ÿ - åŸºäºå‘é‡æ£€ç´¢çš„è®°å¿†ç®¡ç†
"""

import json
import os
from typing import List, Dict, Optional, Any
from datetime import datetime
import numpy as np
from sentence_transformers import SentenceTransformer


class Memory:
    """å•æ¡è®°å¿†"""
    
    def __init__(
        self,
        character_name: str,
        content: str,
        memory_type: str,  # "dialogue", "event", "action", "observation"
        timestamp: Optional[str] = None,
        metadata: Optional[Dict] = None,
        embedding: Optional[np.ndarray] = None
    ):
        self.character_name = character_name
        self.content = content
        self.memory_type = memory_type
        self.timestamp = timestamp or datetime.now().isoformat()
        self.metadata = metadata or {}
        self.embedding = embedding
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºå­˜å‚¨ï¼‰"""
        return {
            "character_name": self.character_name,
            "content": self.content,
            "memory_type": self.memory_type,
            "timestamp": self.timestamp,
            "metadata": self.metadata,
            "embedding": self.embedding.tolist() if self.embedding is not None else None
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'Memory':
        """ä»å­—å…¸åˆ›å»º"""
        if data.get("embedding"):
            data["embedding"] = np.array(data["embedding"])
        return cls(**{k: v for k, v in data.items() if k != 'embedding' or v is not None})


class MemorySystem:
    """è§’è‰²è®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self, model_name: str = "paraphrase-multilingual-MiniLM-L12-v2", storage_dir: str = "memory_storage", model_dir: str = None):
        """
        åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
        
        Args:
            model_name: sentence-transformers æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨æ”¯æŒå¤šè¯­è¨€çš„æ¨¡å‹
            storage_dir: è®°å¿†å­˜å‚¨ç›®å½•
            model_dir: æ¨¡å‹å­˜å‚¨ç›®å½•ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„modelæ–‡ä»¶å¤¹ï¼‰
        """
        self.model_name = model_name
        self.storage_dir = storage_dir
        self.model = None
        self.memories: Dict[str, List[Memory]] = {}  # character_name -> List[Memory]
        
        # è®¾ç½®æ¨¡å‹ç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„model_dirï¼Œå¦åˆ™ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„modelæ–‡ä»¶å¤¹
        if model_dir:
            self.model_dir = model_dir
        else:
            # è·å–é¡¹ç›®æ ¹ç›®å½•
            # backendæ–‡ä»¶çš„è·¯å¾„ï¼šbackend/memory_system.py
            # modelç›®å½•åœ¨ï¼šmodel/
            # éœ€è¦ä»backendçš„çˆ¶ç›®å½•ï¼ˆprojectæ ¹ç›®å½•ï¼‰è·³åˆ°modelç›®å½•
            backend_dir = os.path.dirname(os.path.abspath(__file__))
            parent_dir = os.path.dirname(backend_dir)
            self.model_dir = os.path.join(parent_dir, "model")
        
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        os.makedirs(storage_dir, exist_ok=True)
    
    def _get_model_path(self) -> str:
        """è·å–æ¨¡å‹å­˜å‚¨è·¯å¾„"""
        # ç›´æ¥ä½¿ç”¨ model_name ä½œä¸ºç›®å½•åï¼Œä¸è¿›è¡Œè½¬æ¢
        model_path = os.path.join(self.model_dir, self.model_name)
        return model_path
    
    def _load_model(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹ï¼ˆå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œä¸è®¿é—®ç½‘ç»œï¼‰"""
        if self.model is None:
            model_path = self._get_model_path()
            print(f"æ­£åœ¨ä»æœ¬åœ°åŠ è½½è®°å¿†æ¨¡å‹: {self.model_name}")
            print(f"  æ¨¡å‹è·¯å¾„: {model_path}")
            
            # æ£€æŸ¥æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_path):
                print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
                print(f"æç¤ºï¼šè¯·å…ˆä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•")
                print(f"  æ–¹å¼1: ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°")
                print(f"         python -c \"from sentence_transformers import SentenceTransformer; m=SentenceTransformer('{self.model_name}'); m.save('{model_path}')\"")
                print(f"  æ–¹å¼2: æ‰‹åŠ¨ä» huggingface ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°ä»¥ä¸‹ç›®å½•:")
                print(f"         {model_path}")
                print(f"  æˆ–è€…è¿è¡Œé¡¹ç›®æ ¹ç›®å½•çš„ä¸‹è½½è„šæœ¬: python download_model.py")
                raise FileNotFoundError(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
            config_file = os.path.join(model_path, "config_sentence_transformers.json")
            if not os.path.exists(config_file):
                print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼Œç¼ºå°‘ config_sentence_transformers.json")
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´: {model_path}")
            
            try:
                # ç›´æ¥ä»æŒ‡å®šè·¯å¾„åŠ è½½æ¨¡å‹
                print(f"  æ­£åœ¨åŠ è½½æ¨¡å‹æ–‡ä»¶...")
                self.model = SentenceTransformer(model_path)
                print(f"âœ… è®°å¿†æ¨¡å‹åŠ è½½å®Œæˆï¼ˆç¦»çº¿æ¨¡å¼ï¼Œè·¯å¾„: {model_path}ï¼‰")
                return
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                print(f"è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´")
                raise
    
    def _get_default_cache_dir(self) -> str:
        """è·å–é»˜è®¤çš„ sentence-transformers ç¼“å­˜ç›®å½•ï¼ˆç”¨äºæç¤ºä¿¡æ¯ï¼‰"""
        if os.name == 'nt':
            return os.path.join(os.environ.get('USERPROFILE', ''), '.cache', 'torch', 'sentence_transformers')
        else:
            return os.path.join(os.path.expanduser('~'), '.cache', 'torch', 'sentence_transformers')
    
    def add_memory(
        self,
        character_name: str,
        content: str,
        memory_type: str,
        metadata: Optional[Dict] = None,
        auto_save: bool = True
    ) -> Memory:
        """
        æ·»åŠ ä¸€æ¡è®°å¿†
        
        Args:
            character_name: è§’è‰²åç§°
            content: è®°å¿†å†…å®¹
            memory_type: è®°å¿†ç±»å‹ (dialogue/event/action/observation)
            metadata: é¢å¤–å…ƒæ•°æ®ï¼ˆå¦‚å¯¹è¯å¯¹è±¡ã€äº‹ä»¶å‚ä¸è€…ç­‰ï¼‰
            auto_save: æ˜¯å¦è‡ªåŠ¨ä¿å­˜åˆ°ç£ç›˜ï¼Œé»˜è®¤ä¸ºTrue
        
        Returns:
            åˆ›å»ºçš„è®°å¿†å¯¹è±¡
        """
        # å»¶è¿ŸåŠ è½½æ¨¡å‹
        self._load_model()
        
        # ç”Ÿæˆå‘é‡åµŒå…¥
        embedding = self.model.encode(content, convert_to_numpy=True)
        
        # åˆ›å»ºè®°å¿†
        memory = Memory(
            character_name=character_name,
            content=content,
            memory_type=memory_type,
            metadata=metadata,
            embedding=embedding
        )
        
        # æ·»åŠ åˆ°è®°å¿†åˆ—è¡¨
        if character_name not in self.memories:
            self.memories[character_name] = []
        self.memories[character_name].append(memory)
        
        # è‡ªåŠ¨ä¿å­˜åˆ°ç£ç›˜
        if auto_save:
            self._save_single_character(character_name)
        
        return memory
    
    def _save_single_character(self, character_name: str):
        """
        ä¿å­˜å•ä¸ªè§’è‰²çš„è®°å¿†åˆ°ç£ç›˜ï¼ˆç”¨äºè‡ªåŠ¨ä¿å­˜ï¼‰
        """
        if character_name not in self.memories:
            return
        
        character_dir = os.path.join(self.storage_dir, character_name)
        os.makedirs(character_dir, exist_ok=True)
        
        # ä¿å­˜ä¸ºJSONLæ ¼å¼
        file_path = os.path.join(character_dir, "memories.jsonl")
        with open(file_path, 'w', encoding='utf-8') as f:
            for memory in self.memories[character_name]:
                f.write(json.dumps(memory.to_dict(), ensure_ascii=False) + '\n')
    
    def retrieve_memories(
        self,
        character_name: str,
        query: str,
        top_k: int = 5,
        memory_types: Optional[List[str]] = None,
        min_similarity: float = 0.3
    ) -> List[Memory]:
        """
        æ£€ç´¢ç›¸å…³è®°å¿†
        
        Args:
            character_name: è§’è‰²åç§°
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„æœ€ç›¸å…³è®°å¿†æ•°é‡
            memory_types: è¿‡æ»¤çš„è®°å¿†ç±»å‹åˆ—è¡¨ï¼ˆNoneè¡¨ç¤ºä¸è¿‡æ»¤ï¼‰
            min_similarity: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
        
        Returns:
            ç›¸å…³è®°å¿†åˆ—è¡¨ï¼ŒæŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        """
        # å»¶è¿ŸåŠ è½½æ¨¡å‹
        self._load_model()
        
        # è·å–è§’è‰²çš„æ‰€æœ‰è®°å¿†
        if character_name not in self.memories or not self.memories[character_name]:
            return []
        
        memories = self.memories[character_name]
        
        # æŒ‰ç±»å‹è¿‡æ»¤
        if memory_types:
            memories = [m for m in memories if m.memory_type in memory_types]
            if not memories:
                return []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åµŒå…¥
        memories_with_embedding = [m for m in memories if m.embedding is not None]
        if not memories_with_embedding:
            return []
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.model.encode(query, convert_to_numpy=True)
        
        # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        similarities = []
        for memory in memories_with_embedding:
            # ä½™å¼¦ç›¸ä¼¼åº¦
            sim = np.dot(query_embedding, memory.embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(memory.embedding) + 1e-9
            )
            similarities.append((sim, memory))
        
        # æ’åºå¹¶è¿‡æ»¤
        similarities.sort(key=lambda x: x[0], reverse=True)
        filtered = [(s, m) for s, m in similarities if s >= min_similarity]
        
        # è¿”å›top_kä¸ª
        return [memory for _, memory in filtered[:top_k]]
    
    def get_recent_memories(
        self,
        character_name: str,
        count: int = 10,
        memory_types: Optional[List[str]] = None
    ) -> List[Memory]:
        """
        è·å–æœ€è¿‘çš„è®°å¿†
        
        Args:
            character_name: è§’è‰²åç§°
            count: è¿”å›çš„è®°å¿†æ•°é‡
            memory_types: è¿‡æ»¤çš„è®°å¿†ç±»å‹åˆ—è¡¨
        
        Returns:
            æœ€è¿‘çš„è®°å¿†åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´é™åºæ’åº
        """
        if character_name not in self.memories:
            return []
        
        memories = self.memories[character_name]
        
        # æŒ‰ç±»å‹è¿‡æ»¤
        if memory_types:
            memories = [m for m in memories if m.memory_type in memory_types]
        
        # æŒ‰æ—¶é—´æ’åº
        memories.sort(key=lambda m: m.timestamp, reverse=True)
        
        return memories[:count]
    
    def get_all_memories(self, character_name: str) -> List[Memory]:
        """è·å–è§’è‰²çš„æ‰€æœ‰è®°å¿†"""
        return self.memories.get(character_name, [])
    
    def format_memories_for_prompt(self, memories: List[Memory]) -> str:
        """
        å°†è®°å¿†æ ¼å¼åŒ–ä¸ºé€‚åˆLLMæç¤ºè¯çš„æ–‡æœ¬
        
        Args:
            memories: è®°å¿†åˆ—è¡¨
        
        Returns:
            æ ¼å¼åŒ–çš„è®°å¿†æ–‡æœ¬
        """
        if not memories:
            return "æ— ç›¸å…³è®°å¿†"
        
        lines = []
        for i, memory in enumerate(memories, 1):
            type_emoji = {
                "dialogue": "ğŸ’¬",
                "event": "ğŸ“…",
                "action": "âš¡",
                "observation": "ğŸ‘ï¸"
            }.get(memory.memory_type, "ğŸ“")
            
            lines.append(f"{i}. {type_emoji} {memory.timestamp[:10]} - {memory.content}")
            if memory.metadata:
                for key, value in memory.metadata.items():
                    lines.append(f"   â”” {key}: {value}")
        
        return "\n".join(lines)
    
    def save_to_disk(self):
        """å°†æ‰€æœ‰è®°å¿†ä¿å­˜åˆ°ç£ç›˜"""
        for character_name, memories in self.memories.items():
            character_dir = os.path.join(self.storage_dir, character_name)
            os.makedirs(character_dir, exist_ok=True)
            
            # ä¿å­˜ä¸ºJSONLæ ¼å¼
            file_path = os.path.join(character_dir, "memories.jsonl")
            with open(file_path, 'w', encoding='utf-8') as f:
                for memory in memories:
                    f.write(json.dumps(memory.to_dict(), ensure_ascii=False) + '\n')
        
        print(f"è®°å¿†å·²ä¿å­˜åˆ° {self.storage_dir}")
    
    def load_from_disk(self):
        """ä»ç£ç›˜åŠ è½½æ‰€æœ‰è®°å¿†"""
        if not os.path.exists(self.storage_dir):
            print(f"è®°å¿†å­˜å‚¨ç›®å½•ä¸å­˜åœ¨: {self.storage_dir}")
            return
        
        self.memories = {}
        
        for character_name in os.listdir(self.storage_dir):
            character_dir = os.path.join(self.storage_dir, character_name)
            if not os.path.isdir(character_dir):
                continue
            
            memories = []
            file_path = os.path.join(character_dir, "memories.jsonl")
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            data = json.loads(line.strip())
                            memory = Memory.from_dict(data)
                            memories.append(memory)
                        except Exception as e:
                            print(f"åŠ è½½è®°å¿†å¤±è´¥ ({character_name}): {e}")
            
            self.memories[character_name] = memories
        
        print(f"å·²ä»ç£ç›˜åŠ è½½ {len(self.memories)} ä¸ªè§’è‰²çš„è®°å¿†")
    
    def clear_memories(self, character_name: Optional[str] = None):
        """
        æ¸…é™¤è®°å¿†
        
        Args:
            character_name: è§’è‰²åç§°ï¼ŒNoneè¡¨ç¤ºæ¸…é™¤æ‰€æœ‰è®°å¿†
        """
        if character_name:
            self.memories[character_name] = []
            print(f"å·²æ¸…é™¤è§’è‰² {character_name} çš„è®°å¿†")
        else:
            self.memories = {}
            print("å·²æ¸…é™¤æ‰€æœ‰è§’è‰²è®°å¿†")